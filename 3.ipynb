{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'C:\\Users\\thats\\Desktop\\ipynb/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d71e7153bbc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                weights = None)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mpre_trained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_weights_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Make all the layers in the pre-trained model non-trainable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thats\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2202\u001b[0m           'first, then load the weights.')\n\u001b[0;32m   2203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2204\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2205\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2206\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\thats\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[1;32mc:\\users\\thats\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'C:\\Users\\thats\\Desktop\\ipynb/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
    "                               include_top = False,\n",
    "                               weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation = 'relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation = 'sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
    "                                  rotation_range = 45,\n",
    "                                  width_shift_range = 0.2,\n",
    "                                  height_shift_range = 0.2,\n",
    "                                  shear_range = 0.2,\n",
    "                                  zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   batch_size = 20,\n",
    "                                                   target_size = (150,150),\n",
    "                                                   class_mode = 'binary')     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        batch_size = 20,\n",
    "                                                        target_size = (150,150),\n",
    "                                                        class_mode = 'binary')\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "52/52 - 46s - loss: 0.0753 - acc: 0.9786 - val_loss: 0.0211 - val_acc: 0.9961\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "                             validation_data = validation_generator,\n",
    "                             epochs = 3,\n",
    "                             verbose = 2,\n",
    "                             callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
